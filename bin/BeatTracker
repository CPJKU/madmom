#!/usr/bin/env python
# encoding: utf-8
"""
BeatTracker beat tracking algorithm.

"""

from __future__ import absolute_import, division, print_function

import argparse
import glob

import numpy as np

from madmom import MODELS_PATH
from madmom.audio.signal import SignalProcessor, FramedSignalProcessor
from madmom.audio.spectrogram import (LogarithmicFilteredSpectrogramProcessor,
                                      SpectrogramDifferenceProcessor)
from madmom.features import ActivationsProcessor
from madmom.features.beats import BeatTrackingProcessor
from madmom.features.tempo import TempoEstimationProcessor
from madmom.ml.nn.nets import RNNProcessor, average_predictions
from madmom.processors import (SequentialProcessor, ParallelProcessor,
                               IOProcessor, io_arguments)


def main():
    """BeatTracker"""

    # define parser
    p = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter, description='''
    The BeatTracker program detects all beats in an audio file according to the
    method described in (while following tempo changes):

    "Enhanced Beat Tracking with Context-Aware Neural Networks"
    Sebastian Böck and Markus Schedl.
    Proceedings of the 14th International Conference on Digital Audio Effects
    (DAFx), 2011.

    Instead of using the originally proposed auto-correlation method to build
    a tempo histogram, a new method based on comb filters is used:

    "Accurate Tempo Estimation based on Recurrent Neural Networks and
     Resonating Comb Filters"
    Sebastian Böck, Florian Krebs and Gerhard Widmer.
    Proceedings of the 16th International Society for Music Information
    Retrieval Conference (ISMIR), 2015.

    This program can be run in 'single' file mode to process a single audio
    file and write the detected beats to STDOUT or the given output file.

    $ BeatTracker single INFILE [-o OUTFILE]

    If multiple audio files should be processed, the program can also be run
    in 'batch' mode to save the detected beats to files with the given suffix.

    $ BeatTracker batch [-o OUTPUT_DIR] [-s OUTPUT_SUFFIX] LIST OF FILES

    If no output directory is given, the program writes the files with the
    detected beats to same location as the audio files.

    The 'pickle' mode can be used to store the used parameters to be able to
    exactly reproduce experiments.

    ''')
    # version
    p.add_argument('--version', action='version', version='BeatTracker.2014')
    # input/output arguments
    io_arguments(p, output_suffix='.beats.txt')
    ActivationsProcessor.add_arguments(p)
    # signal processing arguments
    SignalProcessor.add_arguments(p, norm=False, gain=0)
    # beat tracking arguments
    TempoEstimationProcessor.add_arguments(p, method='comb', min_bpm=40,
                                           max_bpm=240, act_smooth=0.09,
                                           hist_smooth=7, alpha=0.79)
    BeatTrackingProcessor.add_arguments(p, look_ahead=10)

    # parse arguments
    args = p.parse_args()

    # set immutable defaults
    args.num_channels = 1
    args.sample_rate = 44100
    args.fps = 100
    args.frame_sizes = [1024, 2048, 4096]
    args.num_bands = 3
    args.fmin = 30
    args.fmax = 17000
    args.norm_filters = True
    args.log = True
    args.mul = 1
    args.add = 1
    args.diff_ratio = 0.5
    args.positive_diffs = True
    args.stack_diffs = np.hstack
    args.nn_files = glob.glob("%s/beats/2013/beats_blstm_[1-8].npz" %
                              MODELS_PATH)

    # print arguments
    if args.verbose:
        print(args)

    # input processor
    if args.load:
        # load the activations from file
        in_processor = ActivationsProcessor(mode='r', **vars(args))
    else:
        # define processing chain
        sig = SignalProcessor(**vars(args))
        # multi-resolution spec & diff
        multi = []
        for args.frame_size in args.frame_sizes:
            frames = FramedSignalProcessor(**vars(args))
            spec = LogarithmicFilteredSpectrogramProcessor(**vars(args))
            diff = SpectrogramDifferenceProcessor(**vars(args))
            # wrap each frame size with spec and diff in a SequentialProcessor
            multi.append(SequentialProcessor((frames, spec, diff)))
        # wrap everything in a ParallelProcessor and stack the features
        multi = ParallelProcessor(multi)
        stack = np.hstack
        # process everything with an RNN and average the predictions
        rnn = RNNProcessor(**vars(args))
        avg = average_predictions
        # sequentially process everything
        in_processor = [sig, multi, stack, rnn, avg]

    # output processor
    if args.save:
        # save the RNN beat activations to file
        out_processor = ActivationsProcessor(mode='w', **vars(args))
    else:
        # track the beats in the activation function
        beat_processor = BeatTrackingProcessor(**vars(args))
        # output handler
        from madmom.utils import write_events as writer
        # sequentially process them
        out_processor = [beat_processor, writer]

    # create an IOProcessor
    processor = IOProcessor(in_processor, out_processor)

    # and call the processing function
    args.func(processor, **vars(args))


if __name__ == '__main__':
    main()
