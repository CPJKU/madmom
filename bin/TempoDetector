#!/usr/bin/env python
# encoding: utf-8
"""
TempoDetector tempo estimation algorithm.

"""

from __future__ import absolute_import, division, print_function

import argparse
import glob

import numpy as np

from madmom import MODELS_PATH
from madmom.audio.signal import SignalProcessor, FramedSignalProcessor
from madmom.audio.spectrogram import (LogarithmicFilteredSpectrogramProcessor,
                                      SpectrogramDifferenceProcessor)
from madmom.features import ActivationsProcessor
from madmom.features.tempo import TempoEstimationProcessor, write_tempo
from madmom.ml.nn.nets import RNNProcessor, average_predictions
from madmom.processors import (SequentialProcessor, ParallelProcessor,
                               IOProcessor, io_arguments)


def main():
    """TempoDetector"""

    # define parser
    p = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter, description='''
    The TempoDetector program detects the dominant tempi according to the
    algorithm described in:

    "Accurate Tempo Estimation based on Recurrent Neural Networks and
     Resonating Comb Filters"
    Sebastian BÃ¶ck, Florian Krebs and Gerhard Widmer.
    Proceedings of the 16th International Society for Music Information
    Retrieval Conference (ISMIR), 2015.

    This program can be run in 'single' file mode to process a single audio
    file and write the detected tempi to STDOUT or the given output file.

    $ TempoDetector single INFILE [-o OUTFILE]

    If multiple audio files should be processed, the program can also be run
    in 'batch' mode to save the detected tempi to files with the given suffix.

    $ TempoDetector batch [-o OUTPUT_DIR] [-s OUTPUT_SUFFIX] LIST OF FILES

    If no output directory is given, the program writes the files with the
    detected tempi to same location as the audio files.

    The 'pickle' mode can be used to store the used parameters to be able to
    exactly reproduce experiments.

    ''')
    # version
    p.add_argument('--version', action='version', version='TempoDetector.2014')
    # input/output options
    io_arguments(p, output_suffix='.bpm.txt')
    ActivationsProcessor.add_arguments(p)
    # signal processing arguments
    SignalProcessor.add_arguments(p, norm=False, gain=0)
    # tempo arguments
    TempoEstimationProcessor.add_arguments(p)
    # mirex stuff
    g = p.add_mutually_exclusive_group()
    g.add_argument('--mirex', dest='tempo_format',
                   action='store_const', const='mirex',
                   help='use the MIREX output format (lower tempo first)')
    g.add_argument('--all', dest='tempo_format',
                   action='store_const', const='all',
                   help='output all detected tempi in raw format')

    # parse arguments
    args = p.parse_args()

    # set immutable defaults
    args.num_channels = 1
    args.sample_rate = 44100
    args.fps = 100
    args.frame_sizes = [1024, 2048, 4096]
    args.num_bands = 3
    args.fmin = 30
    args.fmax = 17000
    args.norm_filters = True
    args.log = True
    args.mul = 1
    args.add = 1
    args.diff_ratio = 0.5
    args.positive_diffs = True
    args.stack_diffs = np.hstack
    args.nn_files = glob.glob("%s/beats/2013/beats_blstm_[1-8].npz" %
                              MODELS_PATH)

    # print arguments
    if args.verbose:
        print(args)

    # input processor
    if args.load:
        # load the activations from file
        in_processor = ActivationsProcessor(mode='r', **vars(args))
    else:
        # define processing chain
        sig = SignalProcessor(**vars(args))
        # multi-resolution spec & diff
        multi = []
        for args.frame_size in args.frame_sizes:
            frames = FramedSignalProcessor(**vars(args))
            spec = LogarithmicFilteredSpectrogramProcessor(**vars(args))
            diff = SpectrogramDifferenceProcessor(**vars(args))
            # wrap each frame size with spec and diff in a SequentialProcessor
            multi.append(SequentialProcessor((frames, spec, diff)))
        # wrap everything in a ParallelProcessor and stack the features
        multi = ParallelProcessor(multi)
        stack = np.hstack
        # process everything with an RNN and average the predictions
        rnn = RNNProcessor(**vars(args))
        avg = average_predictions
        # sequentially process everything
        in_processor = [sig, multi, stack, rnn, avg]

    # output processor
    if args.save:
        # save the RNN beat activations to file
        out_processor = ActivationsProcessor(mode='w', **vars(args))
    else:
        # tempo estimation based on the beat activation function
        tempo_estimator = TempoEstimationProcessor(**vars(args))
        # output handler
        if args.tempo_format == 'mirex':
            # output in the MIREX format (i.e. slower tempo first)
            from functools import partial
            writer = partial(write_tempo, mirex=True)
        elif args.tempo_format in ('raw', 'all'):
            # borrow the event writer for outputting multiple values
            from madmom.utils import write_events as writer
        else:
            # normal output
            writer = write_tempo
        # sequentially process them
        out_processor = [tempo_estimator, writer]

    # create an IOProcessor
    processor = IOProcessor(in_processor, out_processor)

    # finally call the processing function (single/batch processing)
    args.func(processor, **vars(args))


if __name__ == '__main__':
    main()
